{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPyMFBYhTyk2Z2IjQs6Ow/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/govind527/Pytorch_Practice/blob/main/pytorch_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9iB9i1Msqxt"
      },
      "outputs": [],
      "source": [
        "## importing libraries\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=datasets.FashionMNIST(\n",
        "    root=\"data\",# where to download the data\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(), ## how we want to transform data\n",
        "    target_transform =None ## wnat to transform labels\n",
        ")\n",
        "\n",
        "test_data=datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download the data\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(), ## how we want to transform data\n",
        "    target_transform =None ## wnat to transform labels\n",
        ")"
      ],
      "metadata": {
        "id": "WRg2oDDNv3qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data),len(test_data)"
      ],
      "metadata": {
        "id": "txuuTaWu0uhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## first training example\n",
        "image,label=train_data[0]\n",
        "image,label"
      ],
      "metadata": {
        "id": "NoVtz6ka1VkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape,label"
      ],
      "metadata": {
        "id": "POk-AVIj1h1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "DsSwtmnl1rEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_id=train_data.class_to_idx\n",
        "class_to_id"
      ],
      "metadata": {
        "id": "qmtwZpHr1yN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "id": "CwWBkCqY18_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## visualizing data"
      ],
      "metadata": {
        "id": "Io-IWv86FTZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image,label=train_data[0]\n",
        "print(image.shape)\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(label);"
      ],
      "metadata": {
        "id": "K0msoJsR2AiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze(),cmap=\"gray\")\n",
        "plt.title(train_data.classes[label])\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "QqxLF43bajKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##torch.manual_seed(42)\n",
        "fig=plt.figure(figsize=(9,9))\n",
        "rows,cols=4,4\n",
        "for i in range(1,rows*cols+1):\n",
        "  random_idx=torch.randint(0,len(train_data),size=[1]).item()\n",
        "  img,label=train_data[random_idx]\n",
        "  fig.add_subplot(rows,cols,i)\n",
        "  plt.imshow(img.squeeze(),cmap=\"gray\")\n",
        "  plt.title(train_data.classes[label])\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "kWpGKswiajC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataloader preparation"
      ],
      "metadata": {
        "id": "YboUtDV4cByi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data"
      ],
      "metadata": {
        "id": "BaRvTvwtaoBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE=32\n",
        "train_dataloader=DataLoader(dataset=train_data,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            shuffle=True)\n",
        "\n",
        "test_dataloader=DataLoader(dataset=test_data,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            shuffle=False)\n",
        "\n",
        "train_dataloader,test_dataloader"
      ],
      "metadata": {
        "id": "sOA5R2RbaoSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train Dataloader : {train_dataloader}\")\n",
        "print(f\"train Dataloader length : {len(train_dataloader)} of batches {BATCH_SIZE}\")\n",
        "print(f\"test Dataloader length : {len(test_dataloader)} of batches {BATCH_SIZE}\")"
      ],
      "metadata": {
        "id": "MesH8BnxaoVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch,train_label_batch=next(iter(train_dataloader))\n",
        "\n",
        "train_features_batch.shape"
      ],
      "metadata": {
        "id": "CXIGLqhOhOEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "random_idx=torch.randint(0,len(train_features_batch),size=[1]).item()\n",
        "img,label=train_features_batch[random_idx],train_label_batch[random_idx]\n",
        "plt.imshow(img.squeeze(),cmap='gray')\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)\n",
        "print(f\"image size: {img.shape}\")\n",
        "print(f\"label : {label} || label size: {label.shape}\")"
      ],
      "metadata": {
        "id": "eFgpUg6QaoX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## building first baseline model for cv"
      ],
      "metadata": {
        "id": "8nCLIkH4lrxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape:int,\n",
        "               hidden_units:int,\n",
        "               output_shape:int\n",
        "               ):\n",
        "    super().__init__()\n",
        "    self.layer_stack=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape,\n",
        "                  out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=output_shape),\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "7EqPsvCZaoao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_0=FashionMNISTModelV0(\n",
        "    input_shape=784,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)\n",
        ").to(\"cpu\")\n",
        "model_0"
      ],
      "metadata": {
        "id": "yX5tjKcQaoc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x=torch.rand([1,1,28,28])\n",
        "model_0(dummy_x)"
      ],
      "metadata": {
        "id": "mCNk4FLEaogc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "KaS_tDZcoR_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper function already exist skip downloading...\")\n",
        "else:\n",
        "  print(\"downloading helper function\")\n",
        "  request=requests.get('https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/refs/heads/main/helper_functions.py')\n",
        "  with open('helper_functions.py','wb') as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "gvIbq2xiuRTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "## setup loss function and optimizer\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer=torch.optim.SGD(params=model_0.parameters(),\n",
        "                          lr=0.1)"
      ],
      "metadata": {
        "id": "iU5lM8EkES8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## creating a funtion to get time of our experiments\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "def print_train_time(start:float,\n",
        "                     end:float,\n",
        "                     device:torch.device=None):\n",
        "  total_time=end-start\n",
        "  print(f\"train timr on {device} : {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "edDuF6UpE1_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm ## to see progress bar\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu=timer()\n",
        "\n",
        "epochs=3 ## small for faster training time\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch} \\n----\")\n",
        "  ## training\n",
        "\n",
        "  train_loss=0\n",
        "  for batch, (X,y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "\n",
        "    ## forward pass\n",
        "    y_pred=model_0(X)\n",
        "\n",
        "    ## calculate loss\n",
        "\n",
        "    loss=loss_fn(y_pred,y)\n",
        "    train_loss+=loss\n",
        "    ##3. optimizer zero grad\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    ## backward\n",
        "    loss.backward()\n",
        "\n",
        "    ##optimizer step\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch% 400==0:\n",
        "      print(f\"looked at {batch*len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
        "  train_loss/=len(train_dataloader)\n",
        "\n",
        "\n",
        "  ##testing\n",
        "\n",
        "  test_loss,test_acc=0,0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in test_dataloader:\n",
        "      test_pred=model_0(X_test)\n",
        "\n",
        "      test_loss+=loss_fn(test_pred,y_test)\n",
        "\n",
        "      test_acc+=accuracy_fn(y_true=y_test,y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    test_loss/=len(test_dataloader)\n",
        "\n",
        "    test_acc/=len(test_dataloader)\n",
        "  print(f\"\\n Train loss: {train_loss:.4f} | test loss : {test_loss:.4f}, test accuracy : {test_acc:.4f}\")\n",
        "\n",
        "train_time_end_on_cpu=timer()\n",
        "tottal_train_time_model_0=print_train_time(start=train_time_start_on_cpu,\n",
        "                                           end=train_time_end_on_cpu,\n",
        "                                           device=str(next(model_0.parameters()).device))"
      ],
      "metadata": {
        "id": "coCUkqQjF6Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(next(model_0.parameters()).device)"
      ],
      "metadata": {
        "id": "fzmA5NAkF6UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## making predictions and model results"
      ],
      "metadata": {
        "id": "2ZPA2chqMOTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model:torch.nn.Module,\n",
        "               data_loader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "  loss,acc=0,0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "      ##X,y=X.to(device),y.to(device)\n",
        "      y_pred=model(X)\n",
        "\n",
        "      loss+=loss_fn(y_pred,y)\n",
        "      acc+=accuracy_fn(y_true=y,\n",
        "                       y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    loss/=len(data_loader)\n",
        "    acc/=len(data_loader)\n",
        "\n",
        "  return {\"model name\" : model.__class__.__name__,\n",
        "          \"model loss\" : loss.item(),\n",
        "          \"model acc\" : acc}\n",
        "\n",
        "model_0_results=eval_model(model=model_0,\n",
        "                           data_loader=test_dataloader,\n",
        "                           loss_fn=loss_fn,\n",
        "                           accuracy_fn=accuracy_fn)\n",
        "\n",
        "model_0_results\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "AJqN5BNYF6OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device ='cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "7s0VbnNXF6K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape:int,\n",
        "               hidden_units:int,\n",
        "               output_shape:int):\n",
        "    super().__init__()\n",
        "    self.stack_layer=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape,\n",
        "                  out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=output_shape),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self,x:torch.Tensor):\n",
        "    return self.stack_layer(x)"
      ],
      "metadata": {
        "id": "E-e1w_BzF6Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_1=FashionMNISTModelV1(input_shape=784,\n",
        "                            hidden_units=10,\n",
        "                            output_shape=len(class_names)).to(device)\n",
        "model_1"
      ],
      "metadata": {
        "id": "6b97dMx3F6GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "BrkjhHTLF6D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer=torch.optim.SGD(params=model_1.parameters(),\n",
        "                          lr=0.1)"
      ],
      "metadata": {
        "id": "RIpRw1W7F6Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## writing functionthe for train and test code"
      ],
      "metadata": {
        "id": "00RHKCUYwkdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_step(model:nn.Module,\n",
        "               data_loader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               optimizer:torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device:torch.device=device):\n",
        "\n",
        "\n",
        "\n",
        "  ## training\n",
        "  model.train()\n",
        "  train_loss, train_acc=0,0\n",
        "  for batch, (X,y) in enumerate(data_loader):\n",
        "    X=X.to(device)\n",
        "    y=y.to(device)\n",
        "\n",
        "    ## forward pass\n",
        "    y_pred=model(X)\n",
        "\n",
        "    ## calculate loss\n",
        "\n",
        "    loss=loss_fn(y_pred,y)\n",
        "    train_loss+=loss\n",
        "\n",
        "    train_acc+=accuracy_fn(y_true=y,y_pred=y_pred.argmax(dim=1))\n",
        "    ##3. optimizer zero grad\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    ## backward\n",
        "    loss.backward()\n",
        "\n",
        "    ##optimizer step\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  train_loss/=len(data_loader)\n",
        "  train_acc/=len(data_loader)\n",
        "  print(f\"train loss : {train_loss:.5f} | train acc : {train_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "gxahpHwjF5_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_step(model:nn.Module,\n",
        "               data_loader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               #optimizer:torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device:torch.device=device):\n",
        "\n",
        "\n",
        "\n",
        "  ## test\n",
        "  model.eval()\n",
        "  test_loss, test_acc=0,0\n",
        "  with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "      X,y=X.to(device),y.to(device)\n",
        "\n",
        "      test_pred=model(X)\n",
        "      test_loss+=loss_fn(test_pred,y)\n",
        "      test_acc+=accuracy_fn(y_true=y,\n",
        "                            y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    test_loss/=len(data_loader)\n",
        "    test_acc/=len(data_loader)\n",
        "\n",
        "    print(f\"test loss : {test_loss:.5f} | test acc : {test_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "z_9ekRB_F58i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "train_time_start_on_gpu=timer()\n",
        "epochs=3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"epoch {epoch} \\n ====\")\n",
        "  train_step(model=model_1,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)\n",
        "\n",
        "  train_step(model=model_1,\n",
        "             data_loader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)\n",
        "\n",
        "train_time_end_on_gpu=timer()\n",
        "\n",
        "total_train_time_model_1=print_train_time(start=train_time_start_on_gpu,\n",
        "                                          end=train_time_end_on_gpu,\n",
        "                                          device=device)\n"
      ],
      "metadata": {
        "id": "D5sdt0n4F554"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model:torch.nn.Module,\n",
        "               data_loader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device=device):\n",
        "  loss,acc=0,0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "      X,y=X.to(device),y.to(device)\n",
        "      y_pred=model(X)\n",
        "\n",
        "      loss+=loss_fn(y_pred,y)\n",
        "      acc+=accuracy_fn(y_true=y,\n",
        "                       y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    loss/=len(data_loader)\n",
        "    acc/=len(data_loader)\n",
        "\n",
        "  return {\"model name\" : model.__class__.__name__,\n",
        "          \"model loss\" : loss.item(),\n",
        "          \"model acc\" : acc}\n"
      ],
      "metadata": {
        "id": "LSt22BKT6Ks-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results=eval_model(model=model_1,\n",
        "                           data_loader=test_dataloader,\n",
        "                           loss_fn=loss_fn,\n",
        "                           accuracy_fn=accuracy_fn,\n",
        "                           device=device)\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "YkERcJQgF51C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "IwqljWyB4lcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Convolutional Neural Network (CNN)"
      ],
      "metadata": {
        "id": "jBf_ZRcke5D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV2(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture that replicates the TinyVGG\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               input_shape:int,\n",
        "               hidden_units:int,\n",
        "               output_shape:int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_2=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.classifier=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,## trick to calculate\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.conv_block_1(x)\n",
        "    #print(x.shape)\n",
        "    x=self.conv_block_2(x)\n",
        "    #print(x.shape)\n",
        "    x=self.classifier(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "ivkjXQal4lfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_2=FashionMNISTModelV2(input_shape=1,\n",
        "                            hidden_units=10,\n",
        "                            output_shape=len(class_names)).to(device)\n",
        "\n",
        "model_2"
      ],
      "metadata": {
        "id": "PrFoda4D4liM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "images=torch.randn(size=(32,3,64,64))\n",
        "\n",
        "test_image=images[0]\n",
        "images.shape,test_image.shape"
      ],
      "metadata": {
        "id": "R9Guqsct4llb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer=nn.Conv2d(in_channels=3,\n",
        "                     out_channels=10,\n",
        "                     kernel_size=3,\n",
        "                     stride=1,\n",
        "                     padding=0)\n",
        "conv_output=conv_layer(test_image)\n",
        "conv_output.shape"
      ],
      "metadata": {
        "id": "6i_uPr8Q4log"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_image_tensor=torch.randn(size=(1,28,28))\n",
        "model_2(rand_image_tensor.unsqueeze(0).to(device))"
      ],
      "metadata": {
        "id": "P7PPlFfrqHPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2(image.unsqueeze(0).to(device))"
      ],
      "metadata": {
        "id": "WSQM3yquF1KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer=torch.optim.SGD(params=model_2.parameters(),lr=0.1)"
      ],
      "metadata": {
        "id": "67Pp5of_p6mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "train_time_start_model_2=timer()\n",
        "\n",
        "epochs=3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch} \\n ---->\")\n",
        "  train_step(model=model_2,\n",
        "             data_loader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)\n",
        "  test_step(model=model_2,\n",
        "             data_loader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             accuracy_fn=accuracy_fn,\n",
        "             device=device)\n",
        "\n",
        "train_time_end_model_2=timer()\n",
        "total_train_time_model_2=print_train_time(start=train_time_start_model_2,\n",
        "                                          end=train_time_end_model_2,\n",
        "                                          device=device)"
      ],
      "metadata": {
        "id": "F1b6FDXMtP_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results=eval_model(model=model_2,\n",
        "                           data_loader=test_dataloader,\n",
        "                           loss_fn=loss_fn,\n",
        "                           accuracy_fn=accuracy_fn,\n",
        "                           device=device)\n",
        "\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "0scvkD2ku5Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "compare_results=pd.DataFrame([model_0_results,\n",
        "                              model_1_results,\n",
        "                              model_2_results\n",
        "                              ])\n",
        "\n",
        "compare_results"
      ],
      "metadata": {
        "id": "y_vAAgNPv3hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_results.set_index(\"model name\")[\"model acc\"].plot(kind='barh')\n",
        "plt.xlabel('accuracy (%)')\n",
        "plt.ylabel(\"model\")"
      ],
      "metadata": {
        "id": "-O3PH_g3wTlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "CDYcVV-mxEqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predition(model:torch.nn.Module,\n",
        "                   data:list,\n",
        "                   device:torch.device=device):\n",
        "  pred_probs=[]\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      sample=torch.unsqueeze(sample,dim=0).to(device)\n",
        "      pred_logit=model(sample)\n",
        "      pred_prob=torch.softmax(pred_logit.squeeze(),dim=0)\n",
        "\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "  return torch.stack(pred_probs)\n",
        "\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "test_samples=[]\n",
        "test_labels=[]\n",
        "for sample,label in random.sample(list(test_data),k=9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "test_samples[0].shape"
      ],
      "metadata": {
        "id": "VdnxRpyA3P51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_samples[0].squeeze(),cmap='gray')\n",
        "plt.title(class_names[test_labels[0]])"
      ],
      "metadata": {
        "id": "cZeH53tb5CMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs=make_predition(model=model_2,data=test_samples)\n",
        "\n",
        "pred_probs[:2]"
      ],
      "metadata": {
        "id": "Bq8CzgA65QU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_classes=pred_probs.argmax(dim=1)\n",
        "pred_classes"
      ],
      "metadata": {
        "id": "ieLGz75K5mmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,9))\n",
        "nrows=3\n",
        "ncols=3\n",
        "for i,sample in enumerate(test_samples):\n",
        "  plt.subplot(nrows,ncols,i+1)\n",
        "  plt.imshow(sample.squeeze(),cmap='gray')\n",
        "\n",
        "  pred_label=class_names[pred_classes[i]]\n",
        "\n",
        "  truth_label=class_names[test_labels[i]]\n",
        "\n",
        "  title_text =f\"Pred: {pred_label} | truth : {truth_label}\"\n",
        "\n",
        "  if pred_label==truth_label:\n",
        "    plt.title(title_text,fontsize=10,c='g')\n",
        "  else:\n",
        "    plt.title(title_text,fontsize=10,c='r')\n",
        "\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "lV0Umf5a54Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## making confusion matrix"
      ],
      "metadata": {
        "id": "3n6Evjzb75-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import torchmetrics\n",
        "from tqdm.auto import tqdm\n",
        "import mlxtend\n",
        "\n",
        "\n",
        "y_preds=[]\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "  for X,y in tqdm(test_dataloader,desc=\"Making Predictions...\"):\n",
        "    X,y=X.to(device),y.to(device)\n",
        "\n",
        "    y_logit=model_2(X)\n",
        "    y_pred=torch.softmax(y_logit.squeeze(),dim=0).argmax(dim=1)\n",
        "\n",
        "    y_preds.append(y_pred.cpu())\n",
        "\n",
        "##print(y_preds)\n",
        "y_pred_tensor=torch.cat(y_preds)\n",
        "y_pred_tensor"
      ],
      "metadata": {
        "id": "7u19ftZU7mWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_pred_tensor)"
      ],
      "metadata": {
        "id": "gUxhwQoc-Pvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import torchmetrics,mlxtend\n",
        "  print(f\"mlxtend version : {mlxtend.__version__}\")\n",
        "  assert int(mlxtend.__version__.split(\".\")[1]>=19, \"mlxtend version should be greater than 19\")\n",
        "\n",
        "except:\n",
        "  !pip install -q torchmetrics -U mlxtend\n",
        "  import torchmetrics,mlxtend\n",
        "  print(f\"mlxtend version : {mlxtend.__version__}\")"
      ],
      "metadata": {
        "id": "WWgrOVWn-U6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "confmat=ConfusionMatrix(task='multiclass', num_classes=len(class_names))\n",
        "confmat_tensor=confmat(preds=y_pred_tensor,\n",
        "                       target=test_data.targets)\n",
        "\n",
        "fig,ax=plot_confusion_matrix(\n",
        "    conf_mat=confmat_tensor.numpy(),\n",
        "    class_names=class_names,\n",
        "    figsize=(7,7)\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "iStdD1te_J9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confmat_tensor"
      ],
      "metadata": {
        "id": "omQCjJAoBMQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving model and loading model"
      ],
      "metadata": {
        "id": "yY35kZrvCCvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH=Path('Models')\n",
        "MODEL_PATH.mkdir(parents=True,\n",
        "                 exist_ok=True)\n",
        "\n",
        "MODEL_NAME=\"03_pytorch_computer_vision_model_2.pth\"\n",
        "MODEL_SAVE_PATH=MODEL_PATH/MODEL_NAME\n",
        "\n",
        "print(f\"saving model : {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_2.state_dict(),\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "Rmmabf6TBXrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "laoded_model_2=FashionMNISTModelV2(input_shape=1,\n",
        "                                   hidden_units=10,\n",
        "                                   output_shape=len(class_names))\n",
        "\n",
        "laoded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "laoded_model_2.to(device)"
      ],
      "metadata": {
        "id": "HLjb1xQlC2-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results"
      ],
      "metadata": {
        "id": "mrL5LJMmDUvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "loaded_model_2_results=eval_model(\n",
        "    model=laoded_model_2,\n",
        "    data_loader=test_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    accuracy_fn=accuracy_fn\n",
        ")\n",
        "\n",
        "loaded_model_2_results"
      ],
      "metadata": {
        "id": "Tpq7oEzgDZNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ystPFCbbD13e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}